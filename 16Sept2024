import pandas as pd
import chainladder as cl
import numpy as np
# Just to suppress warnings that the one of the date functions in the chainladder package is going to be out of date
import warnings
from datetime import datetime
import os

#---------------------------------------------------------------------------------------------------------------------------------------
# Setting up the environment

# Suppresses the warnings
warnings.filterwarnings("ignore")

# Reading in the data
dat = pd.read_csv("Transactions_Data.csv")
print(dat)

#---------------------------------------------------------------------------------------------------------------------------------------
# Formatting the data

# Finding the start origin year 
start_year = int(min(dat["origin_date"].str.slice(start = -4)))
#print("Start year is: ", start_year)

# Finding the accident year for each claim
dat["AccidentYear"] = dat["origin_date"].str.slice(start = -4)
dat['AccidentYear'] = dat['AccidentYear'].astype(int)

# Finding the year of transaction for each transaction
dat["TransactionYear"] = dat["transaction_date"].str.slice(start = -4)
dat['TransactionYear'] = dat['TransactionYear'].astype(int)

# Finding the month of the accident for each claim
dat["AccidentMonth"] = dat["origin_date"].str.slice(start = -7, stop = -5)
dat['AccidentMonth'] = dat['AccidentMonth'].astype(int)

# Finding the month of transaction for each transaction
dat["TransactionMonth"] = dat["transaction_date"].str.slice(start = -7, stop = -5)
dat['TransactionMonth'] = dat['TransactionMonth'].astype(int)

# Finding the Class for each claim
dat["Class"] = dat["class"].str[0:6]

# Finding the Region for each claim
dat["Region"] = dat["class"].str[7:14]

#  Fiding the Type for each claim
dat["Type"] = dat["class"].str[15:20]

#---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# Obtaining the other features that are going to be used in the new model

# Converting dates to a date_time format
dat["report_date"] = pd.to_datetime(dat["report_date"], format='%d/%m/%Y')
dat["close_date"] = pd.to_datetime(dat["close_date"], format='%d/%m/%Y')
dat["transaction_date"] = pd.to_datetime(dat["transaction_date"], format='%d/%m/%Y')
dat["origin_date"] = pd.to_datetime(dat["origin_date"], format='%d/%m/%Y')

# Reporting delay
dat["AccToReportDays"] = (dat["report_date"] - dat["origin_date"]).dt.days

# Settlement delay
dat["CloseToReportDays"] = (dat["close_date"] - dat["report_date"]).dt.days

# Case estimates
indices = dat.reset_index().groupby(["claim_no"])["index"].min().to_list()
indices = sorted(indices)
unique_claim_dat = dat.iloc[indices,]
unique_claim_dat["CaseEstimates"] = unique_claim_dat["incurred_inc"]
#print("This is the data set with unique claim ids:","\n", case_dat)

# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
# CATEGORICAL VARIABLES 
# One-hot encoding of the categorical variables
dummies_class = pd.get_dummies(unique_claim_dat.Class)
dummies_region = pd.get_dummies(unique_claim_dat.Region)
dummies_type = pd.get_dummies(unique_claim_dat.Type)
unique_claim_dat = pd.concat([unique_claim_dat,dummies_class, dummies_region, dummies_type],axis=1)
print(unique_claim_dat)

#---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# Setting the valuation date 
val_year = 2015
val_month = 6

#----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# APPLYING THE NEW MODEL
# Subsetting the feature dataset to the valuation date

val_unique_claim_dat = unique_claim_dat[(unique_claim_dat["TransactionYear"] < (val_year)) | ((unique_claim_dat["TransactionYear"] == (val_year)) & (unique_claim_dat["TransactionMonth"] < (val_month + 1)))]

# Function to determine the Euclidean distance for numeric features
def euclidean_distance(data, column): 
    # Finding what column a feature is
    col_number = data.columns.get_loc(column)

    #Setting up an empty matrix to store the output of the for loops
    euclidean_dist = [[0 for _ in range(len(data))] for _ in range(len(data))]

    # Determining the Euclidean distance between each claim for the numerical feature
    for claim1 in range(len(data)): 
        for claim2 in range(len(data)): 
            euclidean_dist[claim1][claim2] = float((data.iloc[claim1,col_number] - data.iloc[claim1,col_number])**2)**(1/2)
        
    euclidean_dat = pd.DataFrame(euclidean_dist)

    return(euclidean_dat)

#AccToReportDist = euclidean_distance(val_unique_claim_dat, "AccToReportDays")
#CloseToReportDist = euclidean_distance(val_unique_claim_dat, "CloseToReportDays")
#CaseEstimateDist = euclidean_distance(val_unique_claim_dat, "CaseEstimates")

# Determine the Euclidean distance for the months
#Setting up an empty matrix to store the output of the for loops
numeric_months = [[0 for _ in range(len(val_unique_claim_dat))] for _ in range(len(val_unique_claim_dat))]

# Finding the column number for the months
#col_number_months = val_unique_claim_dat.columns.get_loc("TransactionMonth")

# Determining the Euclidean distance between each claim for the numerical feature
#for claim1 in range(len(val_unique_claim_dat)): 
#    print(claim1)
#    for claim2 in range(len(val_unique_claim_dat)): 
#        numeric_months[claim1][claim2] = min(abs(unique_claim_dat.iloc[claim1,col_number_months]-unique_claim_dat.iloc[claim2,col_number_months]),12-abs(unique_claim_dat.iloc[claim1,col_number_months]-unique_claim_dat.iloc[claim2,col_number_months]))
        
#monthsDist = pd.DataFrame(numeric_months)
#print(monthsDist)

#----------------------------------------------------------------------------------------------------------------------------
# Applying the basic chain ladder 

# Subsetting the claims data to claims that occurred before the valuation date
val_dat = dat[(dat["TransactionYear"] < (val_year)) | ((dat["TransactionYear"] == (val_year)) & (dat["TransactionMonth"] < (val_month + 1)))]
#print("this is the valuation dataframe rolled back:", "\n", val_dat)

val_triangle = cl.Triangle(
    val_dat,
    origin = ["AccidentYear", "AccidentMonth"],
    origin_format = "%d-%m-%Y",    
    development = ["TransactionYear", "TransactionMonth"],
    development_format = "%d-%m-%Y",
    columns = "incurred_inc",
    cumulative = False
)

# Changes the triangle from incremental to cumulative 
val_triangle = val_triangle.incr_to_cum()

# The cumulative incurred claims triangle as at valuation date
print("The cumulative incurred traingle as at the valuation date:","\n", val_triangle)

# Check: the valuation date of the triangle
print("Check: the valuation date of the model is:","\n", val_triangle.valuation_date)

# The full triangle after applying the chain ladder
val_triangle_model = cl.Chainladder().fit(val_triangle)
full_triangle_df = val_triangle_model.full_triangle_.to_frame()
print("The valuataion triangle after the chain ladder has been applied:","\n", full_triangle_df)
#print(full_triangle_df.iloc[1,1])

# The predicted ultimate values for each origin year 
predicted_ultimate = val_triangle_model.ultimate_
predicted_ultimate = predicted_ultimate.to_frame()
predicted_ultimate = predicted_ultimate.rename(columns={'2261-12': 'Predicted'})
print("These are the predicted ultimate values:","\n", predicted_ultimate)

# Finding the observed ultimate corresponding to the same period as the predicted ultimate
# Converting the data to triangle format - all the data is used
initial = cl.Triangle(
    dat, 
    origin = ["AccidentYear", "AccidentMonth"],
    origin_format = "%d-%m-%Y",    
    development = ["TransactionYear", "TransactionMonth"],
    development_format = "%d-%m-%Y",
    columns = "incurred_inc",
    cumulative = False
)

# Converting the triangle from incremental to cumulative
initial = initial.incr_to_cum()
#print("This is the full period, cumulative traingle: ", initial)

# Finding the link ratios
#print(initial.link_ratio)

# Check: the valuation date
#print("This is the valuation date for the full period:", initial.valuation_date)

initial_triangle_dat = initial.to_frame()
observed_ultimate = initial_triangle_dat.iloc[0:((val_year - start_year + 1)*12), (val_year - start_year)*12] 

# Combining the predicted and observed ultimate values into a single dataframe
predicted_ultimate["Observed"] = observed_ultimate
ultimate = predicted_ultimate
print("Data frame of the predicted and observed ultimate:","\n", ultimate)

# Ratio of predicted ultimate to observed ultimate 
print("Predicted:Observed ultimate:","\n", (ultimate["Predicted"]/ultimate["Observed"]))
